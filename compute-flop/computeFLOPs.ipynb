{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the number of floating point operations of a model\n",
    "\n",
    "For models running in the hardware triggering system of a particle detector, the model latency and resource consumption is equally as important as the model accuracy. A reasonable trade-off between the two must therefore be made, often accomplished by iteratively compressing and synthesizing the model to get an accurate resource/latency estimate.\n",
    "\n",
    "Since evaluating the DNN firmware of your algorithm is slightly out of the scope for this challenge (although we do encourage you to give it a try! If you have a Vivado license, have a look at the [hls4ml tutorials](https://github.com/fastmachinelearning/hls4ml-tutorial) and see what you get!), we will instead count the number of floating point operations (FLOPs)in the model, giving us a reasonable idea of the model size and hence resource consumption.\n",
    "\n",
    "Three examples are provided: Using the Tensorflow graph, using the keras-flops tool and one back of the envelope calculation. The examples below are for Tensorflow Keras models and must be adapted if using other libraries.\n",
    "\n",
    "This code is based on TensorFlow 2.3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the autoencoder\n",
    "\n",
    "We'll use the fully connected dense neural network autoencoder for this demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 13:31:57.902632: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-08 13:31:58.100608: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-08 13:31:58.731261: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/amdesai/HEP-Softwares/marty-public/install/lib:/home/amdesai/HEP-Softwares/ROOT/install/lib:/home/amdesai/HEP-Softwares/fastjet-install/lib:/home/amdesai/HEP-Softwares/lhapdf_install/lib:/home/amdesai/HEP-Softwares/ROOT/install/lib:/usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-08 13:31:58.731340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/amdesai/HEP-Softwares/marty-public/install/lib:/home/amdesai/HEP-Softwares/ROOT/install/lib:/home/amdesai/HEP-Softwares/fastjet-install/lib:/home/amdesai/HEP-Softwares/lhapdf_install/lib:/home/amdesai/HEP-Softwares/ROOT/install/lib:/usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-11-08 13:31:58.731347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 57)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 25)           1425        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 20)           500         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_mean_1 (Dense)               (None, 6)            126         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 6)            126         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " custom_func (custom_func)      (None, 6)            0           ['z_mean_1[0][0]',               \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            36          ['custom_func[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 20)           120         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 25)           500         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 57)           1482        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,315\n",
      "Trainable params: 4,315\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 13:32:00.259763: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-11-08 13:32:00.259802: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: amdesai\n",
      "2022-11-08 13:32:00.259808: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: amdesai\n",
      "2022-11-08 13:32:00.259905: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.65.7\n",
      "2022-11-08 13:32:00.259924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.7\n",
      "2022-11-08 13:32:00.259928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.65.7\n",
      "2022-11-08 13:32:00.260173: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation, Layer, ReLU, LeakyReLU\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense, BatchNormalization, Activation, Layer, ReLU, LeakyReLU\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from keras.callbacks import ModelCheckpoint# build model\n",
    "input_shape = 57\n",
    "latent_dimension = 6\n",
    "#num_nodes=[40,30,20]\n",
    "\n",
    "#num_nodes=[25,20]\n",
    "num_nodes=[25,20]\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "\n",
    "class custom_func(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batches = tf.shape(z_mean)[0]\n",
    "        dimension = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batches, dimension))\n",
    "        return z_mean + tf.exp(-1*(z_log_var)*(z_log_var)) * epsilon + tf.exp(-1*z_mean) * epsilon\n",
    "\n",
    "\n",
    "inputArray = keras.Input(shape=(57))\n",
    "x = Dense(num_nodes[0], activation='LeakyReLU',use_bias=False)(inputArray)\n",
    "x = Dense(num_nodes[1], activation='LeakyReLU',use_bias=False)(x)\n",
    "\n",
    "z_mean_1 = layers.Dense(latent_dimension, activation='ReLU', name=\"z_mean_1\")(x)\n",
    "z_log_var = layers.Dense(latent_dimension, activation='ReLU', name=\"z_log_var\")(x)\n",
    "z_1 = custom_func()([z_mean_1, z_log_var])\n",
    "\n",
    "bottle_neck = Dense(latent_dimension, activation='LeakyReLU',use_bias=False)(z_1)\n",
    "\n",
    "x = Dense(num_nodes[1], activation='LeakyReLU',use_bias=False)(bottle_neck)\n",
    "x = Dense(num_nodes[0], activation='LeakyReLU',use_bias=False)(x)\n",
    "\n",
    "decoder = Dense(input_shape)(x)\n",
    "#create autoencoder\n",
    "autoencoder = Model(inputs = inputArray, outputs=decoder)\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer = tf.keras.optimizers.Adam(), loss='mse')\n",
    "\n",
    "autoencoder.save('ae.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Example 1: Using the TF graph\n",
    "Use the TF graph to profile the model and get the total number of floating point ops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: custom_func. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mreset_default_graph()\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flops\u001b[38;5;241m.\u001b[39mtotal_float_ops\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF Profile: Total number of FLOPs =  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mget_flops\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mget_flops\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m----> 7\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mae.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         run_meta \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mRunMetadata()\n\u001b[1;32m     10\u001b[0m         opts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mProfileOptionBuilder\u001b[38;5;241m.\u001b[39mfloat_operation()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/generic_utils.py:605\u001b[0m, in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m get_registered_object(class_name, custom_objects, module_objects)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject is passed to the `custom_objects` argument. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    611\u001b[0m     )\n\u001b[1;32m    613\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# Check if `cls_config` is a list. If it is a list, return the class and the\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# associated class configs for recursively deserialization. This case will\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# happen on the old version of sequential model (e.g. `keras_version` ==\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# \"2.0.6\"), which is serialized in a different structure, for example\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# \"{'class_name': 'Sequential',\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m#   'config': [{'class_name': 'Embedding', 'config': ...}, {}, ...]}\".\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: custom_func. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "def get_flops():\n",
    "    session = tf.compat.v1.Session()\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        with session.as_default():\n",
    "            model = tf.keras.models.load_model('ae.h5')\n",
    "            \n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "            # Optional: save printed results to file\n",
    "            # flops_log_path = os.path.join(tempfile.gettempdir(), 'tf_flops_log.txt')\n",
    "            # opts['output'] = 'file:outfile={}'.format(flops_log_path)\n",
    "\n",
    "            # We use the Keras session graph in the call to the profiler.\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph,\n",
    "                                                  run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "\n",
    "print('TF Profile: Total number of FLOPs =  {}'.format(get_flops()))\n",
    "# Profile:\n",
    "# node name | # float_ops\n",
    "# Mul                      2.02k float_ops (100.00%, 49.95%)\n",
    "# Add                      2.02k float_ops (50.05%, 49.93%)\n",
    "# Sub                          5 float_ops (0.12%, 0.12%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this model has 4,054 floating point operations. Check your terminal for some more detailed per-layer information. If your model is a Keras/TensorFlow model we recommend using this way of estimating the FLOPs.\n",
    "\n",
    "However, if you are for some reason forced to compute it by hand, you can find an example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Doing a back of the envelope calculation\n",
    "\n",
    "Below you can find an example of how to compute the FLOPs of a linear/conv2D layer (based on [keras-Opcounter](https://github.com/kentaroy47/keras-Opcounter)), not taking the activations into account. One multiply-and-accumulate (MAC) operation is counted as 2 FLOPs, and one ADD is counted as one FLOP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_linear(layers):\n",
    "    MAC = layers.output_shape[1] * layers.input_shape[1]\n",
    "    if layers.get_config()[\"use_bias\"]:\n",
    "        ADD = layers.output_shape[1]\n",
    "    else:\n",
    "        ADD = 0\n",
    "    return MAC*2 + ADD\n",
    "\n",
    "def count_conv2d(layers, log = False):\n",
    "    if log:\n",
    "        print(layers.get_config())\n",
    "\n",
    "    numshifts = int(layers.output_shape[1] * layers.output_shape[2])\n",
    "    \n",
    "    MACperConv = layers.get_config()[\"kernel_size\"][0] * layers.get_config()[\"kernel_size\"][1] * layers.input_shape[3] * layers.output_shape[3]\n",
    "    \n",
    "    if layers.get_config()[\"use_bias\"]:\n",
    "        ADD = layers.output_shape[3]\n",
    "    else:\n",
    "        ADD = 0\n",
    "        \n",
    "    return MACperConv * numshifts * 2 + ADD\n",
    "\n",
    "def profile(model, log = False):\n",
    "\n",
    "    layer_name = []\n",
    "    layer_flops = []\n",
    "    inshape = []\n",
    "    weights = []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if \"act\" in layer.get_config()[\"name\"]:\n",
    "          print (\"Skipping ativation functions\")\n",
    "           \n",
    "        elif \"dense\" in layer.get_config()[\"name\"] or \"fc\" in layer.get_config()[\"name\"]:\n",
    "            layer_flops.append(count_linear(layer))\n",
    "            layer_name.append(layer.get_config()[\"name\"])\n",
    "            inshape.append(layer.input_shape)\n",
    "            weights.append(int(np.sum([K.count_params(p) for p in (layer.trainable_weights)])))\n",
    "            \n",
    "        elif \"conv\" in layer.get_config()[\"name\"] and \"pad\" not in layer.get_config()[\"name\"] and \"bn\" not in layer.get_config()[\"name\"] and \"relu\" not in layer.get_config()[\"name\"] and \"concat\" not in layer.get_config()[\"name\"]:\n",
    "            layer_flops.append(count_conv2d(layer,log))\n",
    "            layer_name.append(layer.get_config()[\"name\"])\n",
    "            inshape.append(layer.input_shape)\n",
    "            weights.append(int(np.sum([K.count_params(p) for p in (layer.trainable_weights)])))\n",
    "            \n",
    "        elif \"res\" in layer.get_config()[\"name\"] and \"branch\" in layer.get_config()[\"name\"]:\n",
    "            layer_flops.append(count_conv2d(layer,log))\n",
    "            layer_name.append(layer.get_config()[\"name\"])\n",
    "            inshape.append(layer.input_shape)\n",
    "            weights.append(int(np.sum([K.count_params(p) for p in (layer.trainable_weights)])))\n",
    "            \n",
    "    return layer_name, layer_flops, inshape, weights\n",
    "\n",
    "def doOPS(model):\n",
    "  print(\"Counting number of FLOPs in model\")\n",
    "\n",
    "  layer_name, layer_flops, inshape, weights = profile(autoencoder)\n",
    "  for name, flop, shape, weight in zip(layer_name, layer_flops, inshape, weights):\n",
    "      print(\"layer:\", name, shape, \" FLOPs:\", flop, \"Weights:\", weight)\n",
    "  totalFlops = sum(layer_flops)\n",
    "  print(\"By hand: Total number of FLOPs = {}\".format(totalFlops) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting number of FLOPs in model\n",
      "layer: dense (None, 57)  FLOPs: 2850 Weights: 1425\n",
      "layer: dense_1 (None, 25)  FLOPs: 1000 Weights: 500\n",
      "layer: dense_2 (None, 6)  FLOPs: 72 Weights: 36\n",
      "layer: dense_3 (None, 6)  FLOPs: 240 Weights: 120\n",
      "layer: dense_4 (None, 20)  FLOPs: 1000 Weights: 500\n",
      "layer: dense_5 (None, 25)  FLOPs: 2907 Weights: 1482\n",
      "By hand: Total number of FLOPs = 8069\n"
     ]
    }
   ],
   "source": [
    "totalGFlops = doOPS(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this back-of-the envelope calculation, there is some difference between this estimate and the one above albeit relatively small. We will therefor prioritize the number returned by tf profile when evaluating contributions, but whenever this is not possible we'll do a double check.\n",
    "\n",
    "## Example 3: Using the keras-flops tool\n",
    "\n",
    "Another minimal-code example one can use, and which is also built on top of tf.profile, is the library [keras-flops](https://pypi.org/project/keras-flops/). This library supports dense, convolutional and pooling layers. Let's give it a try too:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install keras-flops?\n",
    "#!pip install keras-flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_flops import get_flops\n",
    "\n",
    "# Let's load the model again so we have a clean graph\n",
    "model = tf.keras.models.load_model('ae.h5')\n",
    "    \n",
    "# Compute FLOPs\n",
    "flops = get_flops(autoencoder, batch_size=1)\n",
    "print(\"keras-flops: Total number of FLOPs = {} \".format(flops))\n",
    "# FLOPS: 4.1e-06 G\n",
    "# _TFProfRoot (--/4.11k flops)\n",
    "#   functional_1/dense/MatMul (1.82k/1.82k flops)\n",
    "#   functional_1/dense_4/MatMul (1.82k/1.82k flops)\n",
    "#   functional_1/dense_3/MatMul (256/256 flops)\n",
    "#   functional_1/dense_1/MatMul (96/96 flops)\n",
    "#   functional_1/dense_4/BiasAdd (57/57 flops)\n",
    "#   functional_1/dense_2/MatMul (48/48 flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
