{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f396425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import tensorflow as tf\n",
    "\n",
    "folder = \"../preprocessing-code/\"\n",
    "filename = \"BKG_dataset.h5\"\n",
    "\n",
    "with h5py.File(folder + filename, \"r\") as file:\n",
    "    X_train = np.array(file[\"X_train\"])\n",
    "    X_test = np.array(file[\"X_test\"])\n",
    "    X_val = np.array(file[\"X_val\"])\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, n_estimators):\n",
    "        self.n_estimators = n_estimators\n",
    "\n",
    "    def IsolationForest(self):\n",
    "        return IsolationForest(n_estimators=self.n_estimators, n_jobs=5, random_state=5)\n",
    "\n",
    "\n",
    "model = Model(40).IsolationForest()\n",
    "\n",
    "autoencoder = model.fit(X_train)\n",
    "bkg_prediction = autoencoder.predict(X_test)\n",
    "bkg_prediction = autoencoder.score_samples(X_test)\n",
    "\n",
    "print(\"SM scanning completed\")\n",
    "\n",
    "signal_labels = [\"Ato4l\", \"hChToTauNu\"]  # , \"hToTauTau\", \"leptoquark\"]\n",
    "\n",
    "# add correct path to signal files\n",
    "signals_file = [\n",
    "    \"Ato4l_lepFilter_13TeV_dataset.h5\",\n",
    "    \"hChToTauNu_13TeV_PU20_dataset.h5\",\n",
    "    #    \"hToTauTau_13TeV_PU20_dataset.h5\",\n",
    "    #    \"leptoquark_LOWMASS_lepFilter_13TeV_dataset.h5\",\n",
    "]\n",
    "\n",
    "signal_data = []\n",
    "for i, label in enumerate(signal_labels):\n",
    "    with h5py.File(folder + signals_file[i], \"r\") as file:\n",
    "        test_data = np.array(file[\"Data\"])\n",
    "    signal_data.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_results = []\n",
    "signal_preds = []\n",
    "for i, label in enumerate(signal_labels):\n",
    "    print(\"now predicting for \", label)\n",
    "    # signal_prediction = autoencoder.predict(signal_data[i])\n",
    "    signal_prediction = autoencoder.score_samples(signal_data[i])\n",
    "    signal_results.append(\n",
    "        [label, signal_data[i], signal_prediction]\n",
    "    )  # save [label, true, prediction] for signal\n",
    "    signal_preds.append(signal_prediction)\n",
    "\n",
    "\n",
    "# print(signal_prediction.shape)\n",
    "\n",
    "\n",
    "def mse_loss(true, prediction):\n",
    "    # print(prediction)\n",
    "    loss = tf.reduce_mean(tf.math.square(true - prediction), axis=-1)\n",
    "    # loss = - tf.reduce_mean(tf.math.log(1-(tf.math.square(true - prediction))),axis=-1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# compute loss value (true, predicted)\n",
    "total_loss = []\n",
    "total_loss.append(\n",
    "    mse_loss(np.ones(X_test.shape[0]), bkg_prediction.astype(np.float32)).numpy()\n",
    ")\n",
    "for i, signal_X in enumerate(signal_data):\n",
    "    # print(signal_X.shape, signal_results[i][2])\n",
    "    total_loss.append(\n",
    "        mse_loss(\n",
    "            -1 * np.ones(signal_X.shape[0]), signal_results[i][2].astype(np.float32)\n",
    "        ).numpy()\n",
    "    )\n",
    "\n",
    "# print(total_loss)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "bin_size = 100\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, label in enumerate(signal_labels):\n",
    "    plt.hist(\n",
    "        total_loss[i],\n",
    "        bins=bin_size,\n",
    "        label=label,\n",
    "        density=True,\n",
    "        histtype=\"step\",\n",
    "        fill=False,\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Autoencoder Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.title(\"MSE loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# # 2.\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "labels = np.concatenate([[\"Background\"], np.array(signal_labels)])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "plt.plot(model.history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model.history.history[\"ACC\"], label=\"Training accuracy\")\n",
    "plt.plot(model.history.history[\"val_ACC\"], label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# print(total_loss)\n",
    "# target_background = np.zeros(total_loss[0].shape[0])\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb52800",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(signal_prediction))\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0:\n",
    "        continue  # background events\n",
    "    # trueVal = np.concatenate((np.ones))\n",
    "    # trueVal = np.concatenate(\n",
    "    #    (np.ones(total_loss[i].shape[0]), target_background)\n",
    "    # )  # anomaly=1, bkg=0\n",
    "    # predVal_loss = np.concatenate((total_loss[i], total_loss[0]))\n",
    "    # print(signal_results[i][2],signal_results[i][2].shape)\n",
    "    trueVal = np.ones(len(signal_preds[i]))\n",
    "    print(trueVal)\n",
    "    predVal_loss = abs(\n",
    "        signal_preds[i]\n",
    "    )  # (signal_results[i][2].astype(np.float32)).numpy() #,signal_results[1][2].astype(np.float32))\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "    for j in range(len(fpr_loss)):\n",
    "        if fpr_loss[j] == 0.00001:\n",
    "            print(label, tpr_loss[j])\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "    print(auc_loss)\n",
    "    plt.plot(\n",
    "        fpr_loss,\n",
    "        tpr_loss,\n",
    "        \"-\",\n",
    "        label=f\"{label} (auc = {auc_loss * 100.0:.1f}%)\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "    plt.semilogx()\n",
    "    plt.semilogy()\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.legend(loc=\"center right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1), np.linspace(0, 1), \"--\", color=\"0.75\")\n",
    "plt.axvline(\n",
    "    0.00001, color=\"red\", linestyle=\"dashed\", linewidth=1\n",
    ")  # threshold value for measuring anomaly detection efficiency\n",
    "plt.title(\"ROC AE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dd28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b9a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
