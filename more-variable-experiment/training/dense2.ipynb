{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.layers import Activation  # LeakyReLU,; ReLU,\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Input, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# In[2]:\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)],\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fde080",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../preprocessing-code/\"\n",
    "filename = \"BKG_dataset.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213415ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(folder + filename, \"r\") as file:\n",
    "    X_train = np.array(file[\"X_train\"])\n",
    "    X_test = np.array(file[\"X_test\"])\n",
    "    X_val = np.array(file[\"X_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 60\n",
    "latent_dimension = 6\n",
    "num_nodes = [28, 18, 10]  # [25,15]#\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1024\n",
    "activation = \"LeakyReLU\"  # LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "inputArray = Input(shape=(input_shape))\n",
    "x = Dense(num_nodes[0], use_bias=False, kernel_initializer=initializer)(inputArray)\n",
    "x = Activation(activation)(x)\n",
    "x = Dense(num_nodes[1], use_bias=False, kernel_initializer=initializer)(x)\n",
    "x = Activation(activation)(x)\n",
    "x = Dense(num_nodes[2], use_bias=False, kernel_initializer=initializer)(x)\n",
    "x = Activation(activation)(x)\n",
    "x = Dense(latent_dimension, use_bias=False, kernel_initializer=initializer)(x)\n",
    "x = Activation(activation)(x)\n",
    "x = Dense(latent_dimension - 3, use_bias=False, kernel_initializer=initializer)(x)\n",
    "encoder = Activation(\"linear\")(x)\n",
    "\n",
    "# decoder\n",
    "x = Dense(num_nodes[2], use_bias=False, kernel_initializer=initializer)(encoder)\n",
    "x = Activation(activation)(x)\n",
    "x = Dense(num_nodes[1], use_bias=False, kernel_initializer=initializer)(x)\n",
    "x = Activation(activation)(x)\n",
    "x = Dense(num_nodes[0], use_bias=False, kernel_initializer=initializer)(x)\n",
    "x = Activation(activation)(x)\n",
    "decoder = Dense(input_shape)(x)\n",
    "\n",
    "# create autoencoder\n",
    "autoencoder = Model(inputs=inputArray, outputs=decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(\n",
    "    optimizer=keras.optimizers.Adam(), loss=\"mse\", metrics=[\"ACC\"]  # , \"AUC\"]\n",
    ")  # ,metrics=['AUC','ACC','MSE']) #loss= \"mse\", mae, msle MeanSquaredLogarithmicError mean_squared_logarithmic_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411971a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\",\n",
    "    min_delta=0.003,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, X_val),\n",
    "    # callbacks=callbacks,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f37ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"model_name\"\n",
    "# model_directory = \"\"\n",
    "# save_model(model_directory + model_name, autoencoder)\n",
    "\n",
    "# ## Prediction - background\n",
    "\n",
    "bkg_prediction = autoencoder.predict(X_test)\n",
    "\n",
    "# add correct signal labels\n",
    "signal_labels = [\"Ato4l\", \"hChToTauNu\", \"hToTauTau\", \"leptoquark\"]\n",
    "\n",
    "# add correct path to signal files\n",
    "signals_file = [\n",
    "    \"Ato4l_lepFilter_13TeV_dataset.h5\",\n",
    "    \"hChToTauNu_13TeV_PU20_dataset.h5\",\n",
    "    \"hToTauTau_13TeV_PU20_dataset.h5\",\n",
    "    \"leptoquark_LOWMASS_lepFilter_13TeV_dataset.h5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4dbcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_data = []\n",
    "for i, label in enumerate(signal_labels):\n",
    "    with h5py.File(folder + signals_file[i], \"r\") as file:\n",
    "        test_data = np.array(file[\"Data\"])\n",
    "    signal_data.append(test_data)\n",
    "    # signal_data = scaler.transform(signal_data)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "signal_results = []\n",
    "\n",
    "for i, label in enumerate(signal_labels):\n",
    "    signal_prediction = autoencoder.predict(signal_data[i])\n",
    "    signal_results.append(\n",
    "        [label, signal_data[i], signal_prediction]\n",
    "    )  # save [label, true, prediction] for signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b098435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(true, prediction):\n",
    "    # loss = tf.reduce_mean(tf.math.abs(1-tf.math.log(true - prediction)), axis=-1)\n",
    "    loss = tf.reduce_mean(tf.math.square(true - prediction), axis=-1)\n",
    "    # loss = - tf.reduce_mean(tf.math.log(1-(tf.math.square(true - prediction))),axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1556a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss value (true, predicted)\n",
    "total_loss = []\n",
    "total_loss.append(mse_loss(X_test, bkg_prediction.astype(np.float32)).numpy())\n",
    "for i, signal_X in enumerate(signal_data):\n",
    "    total_loss.append(\n",
    "        mse_loss(signal_X, signal_results[i][2].astype(np.float32)).numpy()\n",
    "    )\n",
    "print(total_loss)\n",
    "bin_size = 100\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, label in enumerate(signal_labels):\n",
    "    plt.hist(\n",
    "        total_loss[i],\n",
    "        bins=bin_size,\n",
    "        label=label,\n",
    "        density=True,\n",
    "        histtype=\"step\",\n",
    "        fill=False,\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Autoencoder Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.title(\"MSE loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "labels = np.concatenate([[\"Background\"], np.array(signal_labels)])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "plt.plot(autoencoder.history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.plot(autoencoder.history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(autoencoder.history.history[\"ACC\"], label=\"Training accuracy\")\n",
    "plt.plot(autoencoder.history.history[\"val_ACC\"], label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "target_background = np.zeros(total_loss[0].shape[0])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0:\n",
    "        continue  # background events\n",
    "\n",
    "    trueVal = np.concatenate(\n",
    "        (np.ones(total_loss[i].shape[0]), target_background)\n",
    "    )  # anomaly=1, bkg=0\n",
    "    predVal_loss = np.concatenate((total_loss[i], total_loss[0]))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "    for j in range(len(fpr_loss)):\n",
    "        if fpr_loss[j] == 0.00001:\n",
    "            print(label, tpr_loss[j])\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "\n",
    "    plt.plot(\n",
    "        fpr_loss,\n",
    "        tpr_loss,\n",
    "        \"-\",\n",
    "        label=f\"{label} (auc = {auc_loss * 100.0:.1f}%)\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "    plt.semilogx()\n",
    "    plt.semilogy()\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.legend(loc=\"center right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1), np.linspace(0, 1), \"--\", color=\"0.75\")\n",
    "plt.axvline(\n",
    "    0.00001, color=\"red\", linestyle=\"dashed\", linewidth=1\n",
    ")  # threshold value for measuring anomaly detection efficiency\n",
    "plt.title(\"ROC AE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b7ff4",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
